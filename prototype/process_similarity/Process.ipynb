{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will pre-process all the images in `image_dir` using the model in `model_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "# This is the model we are using, straight out of DIGITS.\n",
    "model_path = '/home/studio/Documents/level19'\n",
    "model_fn = path.join(model_path, 'snapshot_iter_205950.caffemodel')\n",
    "deploy_fn = path.join(model_path, 'deploy.prototxt')\n",
    "mean_fn = path.join(model_path, 'mean.binaryproto')\n",
    "\n",
    "# These are where the files are that we want to process.\n",
    "image_dir = '/home/studio/Desktop/results/download_county/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the libraries we'll be using and define a couple helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in xrange(0, len(l), n):\n",
    "        yield l[i:i+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "def list_all_files(directory, extensions=None):\n",
    "    for root, dirnames, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            base, ext = os.path.splitext(filename)\n",
    "            joined = os.path.join(root, filename)\n",
    "            if extensions is None or ext.lower() in extensions:\n",
    "                yield joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load pycaffe, the Python wrapper for Caffe. Adding the pycaffe root to the system path is a little bit of a hack, but we can't always add it correctly. All the warnings can be ignored according to [this post](https://groups.google.com/forum/#!msg/caffe-users/LZjsJFRzfcU/TVm24uIQCQAJ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio/Documents/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Net<float> > already registered; second conversion method ignored.\n",
      "  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \\\n",
      "/home/studio/Documents/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Blob<float> > already registered; second conversion method ignored.\n",
      "  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \\\n",
      "/home/studio/Documents/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Solver<float> > already registered; second conversion method ignored.\n",
      "  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \\\n"
     ]
    }
   ],
   "source": [
    "pycaffe_root = '/home/studio/Documents/caffe/python'\n",
    "sys.path.insert(0, pycaffe_root)\n",
    "import caffe\n",
    "from caffe.proto import caffe_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A big chunk of this code is based on the [classification example](https://github.com/NVIDIA/DIGITS/blob/master/examples/classification/example.py) that comes with DIGITS, with only minor modifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_net(caffemodel, deploy_file, use_gpu=True):\n",
    "    if use_gpu:\n",
    "        caffe.set_mode_gpu()\n",
    "    return caffe.Net(deploy_file, caffemodel, caffe.TEST)\n",
    "\n",
    "def get_transformer(deploy_file, mean_file=None):\n",
    "    network = caffe_pb2.NetParameter()\n",
    "    with open(deploy_file) as infile:\n",
    "        text_format.Merge(infile.read(), network)\n",
    "\n",
    "    if network.input_shape:\n",
    "        dims = network.input_shape[0].dim\n",
    "    else:\n",
    "        dims = network.input_dim[:4]\n",
    "\n",
    "    t = caffe.io.Transformer(inputs = {'data': dims})\n",
    "    t.set_transpose('data', (2,0,1)) # transpose to (channels, height, width)\n",
    "\n",
    "    # color images\n",
    "    if dims[1] == 3:\n",
    "        # channel swap\n",
    "        t.set_channel_swap('data', (2,1,0))\n",
    "\n",
    "    if mean_file:\n",
    "        # set mean pixel\n",
    "        with open(mean_file,'rb') as infile:\n",
    "            blob = caffe_pb2.BlobProto()\n",
    "            blob.MergeFromString(infile.read())\n",
    "            if blob.HasField('shape'):\n",
    "                blob_dims = blob.shape\n",
    "                assert len(blob_dims) == 4, 'Shape should have 4 dimensions - shape is \"%s\"' % blob.shape\n",
    "            elif blob.HasField('num') and blob.HasField('channels') and \\\n",
    "                    blob.HasField('height') and blob.HasField('width'):\n",
    "                blob_dims = (blob.num, blob.channels, blob.height, blob.width)\n",
    "            else:\n",
    "                raise ValueError('blob does not provide shape or 4d dimensions')\n",
    "            pixel = np.reshape(blob.data, blob_dims[1:]).mean(1).mean(1)\n",
    "            t.set_mean('data', pixel)\n",
    "\n",
    "    return t\n",
    "\n",
    "def load_image(path, height, width):\n",
    "    image = PIL.Image.open(path)\n",
    "    image = image.convert('RGB')\n",
    "    image = np.array(image)\n",
    "    # squash\n",
    "    image = scipy.misc.imresize(image, (height, width), 'bilinear')\n",
    "    return image\n",
    "\n",
    "def encode(images, net, transformer):\n",
    "    caffe_images = []\n",
    "    for image in images:\n",
    "        if image.ndim == 2:\n",
    "            caffe_images.append(image[:,:,np.newaxis])\n",
    "        else:\n",
    "            caffe_images.append(image)\n",
    "\n",
    "    caffe_images = np.array(caffe_images)\n",
    "\n",
    "    dims = transformer.inputs['data'][1:]\n",
    "\n",
    "    new_shape = (len(images),) + tuple(dims)\n",
    "    if net.blobs['data'].data.shape != new_shape:\n",
    "        net.blobs['data'].reshape(*new_shape)\n",
    "    for index, image in enumerate(images):\n",
    "        image_data = transformer.preprocess('data', image)\n",
    "        net.blobs['data'].data[index] = image_data\n",
    "    net.forward()\n",
    "    class_key = net.blobs.keys()[-1]\n",
    "    code_key = net.blobs.keys()[-3]\n",
    "    class_data = np.copy(net.blobs[class_key].data)\n",
    "    code_data = np.copy(net.blobs[code_key].data).reshape(len(images), -1)\n",
    "    return class_data, code_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the network from disk, which can take up to 10 seconds the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 152 ms, sys: 1.36 s, total: 1.52 s\n",
      "Wall time: 1.53 s\n"
     ]
    }
   ],
   "source": [
    "%time net = get_net(model_fn, deploy_fn)\n",
    "transformer = get_transformer(deploy_fn, mean_fn)\n",
    "_, channels, height, width = transformer.inputs['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we recursively list all 500k files in our target directory, which can also take up to 10 seconds the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.04 s, sys: 3.4 s, total: 6.44 s\n",
      "Wall time: 9.32 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "571771"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time filenames = list(list_all_files(image_dir, ['.jpeg', '.png']))\n",
    "np.savetxt('filenames.txt', filenames, fmt='%s')\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After saving the filenames to disk we double check that we didn't miss any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571771 filenames.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l filenames.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that we can load the filenames from disk, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "571771"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('filenames.txt', 'r') as f:\n",
    "    filenames = [line.strip() for line in f.readlines()]\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the classification in batches, and print a note about our progress every so often, and save a checkpoint file every so often. In general, a larger batch size is going to go faster per image, but at some point we will run out of memory. After setting these variables we run the batch process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "checkpoint_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: 78.22 images/second, saving.\n",
      "Batch 100: 85.77 images/second, saving.\n"
     ]
    }
   ],
   "source": [
    "classify_start_time = time.time()\n",
    "\n",
    "all_code_data = None\n",
    "all_class_data = None\n",
    "class_fn = path.join(model_path, 'all_class_data.npy')\n",
    "code_fn = path.join(model_path, 'all_code_data.npy')\n",
    "for i, filename_chunk in enumerate(chunks(filenames, batch_size)):\n",
    "    images = [load_image(fn, height, width) for fn in filename_chunk]\n",
    "    chunk_start_time = time.time()\n",
    "    class_data, code_data = encode(images, net, transformer)\n",
    "    if all_code_data is None:\n",
    "        all_class_data = class_data\n",
    "        all_code_data = code_data\n",
    "    else:\n",
    "        all_class_data = np.vstack((all_class_data, class_data))\n",
    "        all_code_data = np.vstack((all_code_data, code_data))\n",
    "    ips = len(filename_chunk) / (time.time() - chunk_start_time)\n",
    "    if i % checkpoint_iter == 0:\n",
    "        print 'Batch %i: %.2f images/second, saving.' % (i, ips)\n",
    "        np.save(class_fn, all_class_data)\n",
    "        np.save(code_fn, all_code_data)\n",
    "        \n",
    "print 'Saving on final iteration.'\n",
    "np.save(class_fn, all_class_data)\n",
    "np.save(code_fn, all_code_data)\n",
    "\n",
    "classify_duration = (time.time() - chunk_start_time)\n",
    "ips = len(filenames) / classify_duration\n",
    "print 'Classified %i images in %.2f seconds at %.2f images/second' % (len(filenames), classify_duration, ips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch processing saved two files: `all_class_data.npy` and `all_code_data.npy`, which capture the last, and second to last layers of the network for each image. After everything is done, we can load the data to check that it didn't miss any images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(571771, 188)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_class_data = np.load(class_fn)\n",
    "all_class_data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
